# -*- coding: utf-8 -*-
"""ANN Model Visualization for Github

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EiF08ovn-74exlQAhSdfPGd-heBPwMrv

#Import Relevant Libraries
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import shap   #You may need to install shap beforehand
from matplotlib.cm import ScalarMappable
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold , train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score , mean_squared_error
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator

"""#Import and Split Data

"""

#We still need data to scale and PCA-reduce the prediction input.
raw_csv_data_pd = pd.read_csv(".../Shuffled_raw_data.csv")
raw_csv_data = raw_csv_data_pd.to_numpy()
shuffled_inputs = raw_csv_data[:,0:-1]
shuffled_targets = raw_csv_data[:,-1]
print("The input data are in dimension",shuffled_inputs.shape)
print("The output data are in dimension",shuffled_targets.shape)

#Splitting Data to train (90%) and test (10%), but test dataset will not be used.
samples_count = shuffled_inputs.shape[0]
train_samples_count = int(0.9 * samples_count)
train_inputs = shuffled_inputs[:train_samples_count]
train_targets = shuffled_targets[:train_samples_count]
test_inputs = shuffled_inputs[train_samples_count:]
test_targets = shuffled_targets[train_samples_count:]
print("The train_input data are in dimension",train_inputs.shape)
print("The test_input data are in dimension",test_inputs.shape)

"""#Scaler and PCA"""

def preprocess(train,validation,test):
  scaler=StandardScaler()
  scaler.fit(train)
  scaled_train_inputs=scaler.transform(train)
  scaled_validation_inputs=scaler.transform(validation)
  scaled_test_inputs=scaler.transform(test)
  X,Y,Z = pca_scale(scaled_train_inputs,scaled_validation_inputs,scaled_test_inputs)
  return X,Y,Z

def pca_scale(train,validation,test):
  pca=PCA(n_components = 9)
  reduced_train_inputs=pca.fit_transform(train)
  reduced_validation_inputs=pca.transform(validation)
  reduced_test_inputs=pca.transform(test)
  return reduced_train_inputs,reduced_validation_inputs,reduced_test_inputs

"""#ANN Visualization"""

#We will use Pipeline to make our code compact.
class CVANN(BaseEstimator):
  def __init__(self):
      pass

  def fit(self, documents, y=None):
      return self
        
  def predict(data):
    pred_data=np.zeros((data.shape[0],10))
    kf = KFold(n_splits=10)
    i=0
    for train_index, validation_index in kf.split(train_targets):
      X_train = train_inputs[train_index]
      scaler=StandardScaler()
      scaled_train=scaler.fit_transform(X_train)
      scaled_data=scaler.transform(data)
      pca=PCA(n_components = 9)
      pca.fit(scaled_train)
      reduced_data=pca.transform(scaled_data)
      filepath = ".../Trained ANN Model 10 folds/ANN model fold "+str(i)
      model = tf.keras.models.load_model(filepath, compile = True)
      pred_data[:,i]=model.predict(reduced_data).reshape(-1,)
      i+=1
    return np.mean(pred_data,axis=1)

pipe = Pipeline(steps=[('all',CVANN)])

"""##Contour plot for %N and %S (Setting 10.01 O% setting 1:1.361:0.714=N5:N6:NQ)"""

#X and Y are the parameters we want to vary
#Input X and Y range
#In this case X represents total nitrogen contents (N5+N6+NQ) and Y represents Sulfur
X_lower_limit , X_upper_limit , number_of_Xincrement = 0 , 10.4 , 301
Y_lower_limit , Y_upper_limit , number_of_Yincrement = 0 , 4.6 , 301

#We create an X and Y array for plt.contourf
X=np.linspace(X_lower_limit , X_upper_limit , number_of_Xincrement)+np.zeros((number_of_Yincrement,1))
Y=np.linspace(Y_lower_limit , Y_upper_limit , number_of_Yincrement).reshape(-1,1)+np.zeros((1,number_of_Xincrement))

#This is for generating 3D INPUT matrix with dimension (number_of_Yincrement,number_of_Xincrement,11) for 2D prediction
#Here you can customize INPUT matrix and select which variable you want to vary according to X and Y
#In this case, we vary N5,N6,NQ according to X and Sulfur accoding to Y
INPUT=np.array([[6,0,324.6,1.12,10.01,0,0,0,0,0,0]])+np.zeros((number_of_Yincrement,number_of_Xincrement,11))
INPUT[:,:,5]=X*1/3.075        #N5
INPUT[:,:,6]=X*1.361/3.075    #N6
INPUT[:,:,7]=X*0.714/3.075    #NQ
INPUT[:,:,9]=Y                #S
INPUT=INPUT.reshape(-1,11)

#Predict using pipeline and input from INPUT pipeline
#The final prediction that will be used for contour plot is in dimension (number_of_Yincrement,number_of_Xincrement)
Z=pipe.predict(INPUT).reshape(number_of_Yincrement,number_of_Xincrement)

#Contour plot
#Contour plot color range
vmin = 0
vmax = 360

fig, ax = plt.subplots()
qcs = ax.contourf(X, Y, Z,150,vmin=vmin, vmax=vmax,cmap='turbo')    #Old versions of matplotlib may not support cmap='turbo'

fig.colorbar(
   ScalarMappable(norm=qcs.norm, cmap='turbo'),
   ticks=range(vmin, vmax+1, 30)
)

ax.set_xlabel("% Nitrogen", fontsize=18)
ax.set_ylabel("% Sulfur", fontsize=18)
#fig.savefig(filepath, dpi=300)
plt.show()

"""##Retention Rate
For the retention rate, the prediction at high and low current densities are divided and percent ratios are plotted in the contor plot.

In this example, we plot the retention rate of 10 A/g wrt 1 A/g

1 A/g
"""

#X and Y are the parameters we want to vary
#Input X and Y range
#In this case X represents total nitrogen contents (N5+N6+NQ) and Y represents Sulfur
X_lower_limit , X_upper_limit , number_of_Xincrement = 0 , 10.4 , 301
Y_lower_limit , Y_upper_limit , number_of_Yincrement = 0 , 4.6 , 301

#We create an X and Y array for plt.contourf
X=np.linspace(X_lower_limit , X_upper_limit , number_of_Xincrement)+np.zeros((number_of_Yincrement,1))
Y=np.linspace(Y_lower_limit , Y_upper_limit , number_of_Yincrement).reshape(-1,1)+np.zeros((1,number_of_Xincrement))

#This is for generating 3D INPUT matrix with dimension (number_of_Yincrement,number_of_Xincrement,11) for 2D prediction
#Here you can customize INPUT matrix and select which variable you want to vary according to X and Y
#In this case, we vary N5,N6,NQ according to X and Sulfur accoding to Y
INPUT_1Ag=np.array([[6,0,324.6,1.12,10.01,0,0,0,0,0,0]])+np.zeros((number_of_Yincrement,number_of_Xincrement,11))
INPUT_1Ag[:,:,5]=X*1/3.075        #N5
INPUT_1Ag[:,:,6]=X*1.361/3.075    #N6
INPUT_1Ag[:,:,7]=X*0.714/3.075    #NQ
INPUT_1Ag[:,:,9]=Y                #S
INPUT_1Ag=INPUT_1Ag.reshape(-1,11)

#Predict capacitance for 1 A/g
Z_1Ag=pipe.predict(INPUT_1Ag).reshape(number_of_Yincrement,number_of_Xincrement)

"""Retention rate 10/1"""

#Now we repeat but change the current density to 10A/g (ln10=2.303)
INPUT_10Ag=np.array([[6,0,324.6,1.12,10.01,0,0,0,0,0,2.303]])+np.zeros((number_of_Yincrement,number_of_Xincrement,11))
INPUT_10Ag[:,:,5]=X*1/3.075        #N5
INPUT_10Ag[:,:,6]=X*1.361/3.075    #N6
INPUT_10Ag[:,:,7]=X*0.714/3.075    #NQ
INPUT_10Ag[:,:,9]=Y                #S
INPUT_10Ag=INPUT_10Ag.reshape(-1,11)

#Predict capacitance for 10 A/g and Retention rate
Z_10Ag=pipe.predict(INPUT_10Ag).reshape(number_of_Yincrement,number_of_Xincrement)
Z=Z_10Ag/Z_1Ag*100

#Contour plot
vmin = 0
vmax = 100    #retention rate in 100% scale

fig, ax = plt.subplots()
qcs = ax.contourf(X, Y, Z,150,vmin=vmin, vmax=vmax,cmap='turbo')

fig.colorbar(
   ScalarMappable(norm=qcs.norm, cmap='turbo'),
   ticks=range(vmin, vmax+1, 10)   
)

ax.set_xlabel("% Nitrogen", fontsize=18)
ax.set_ylabel("% Sulfur", fontsize=18)
#fig.savefig(filepath, dpi=300)
plt.show()

"""#SHAP Values
We have provided code for calculating SHAP value of a single prediction including shap force plot and shap value table.

"""

#We want to make a prediction at tester_df (total nitrogen is set to 3% and sulfur to 2%)
#We use pandas dataframe version of test_inputs and tester_df
#We are using test_input as the background data
#Note that shuffled_inputs could also be used at the cost of runtime
test_input_df = pd.DataFrame(test_inputs , columns= ['KOH (M)','H2SO4 (M)','SSA','ID/IG','%O','%N5','%N6','%NQ','%OtherN','%S','ln(Current Density)'])
tester_df = pd.DataFrame(np.array([6,0,324.6,1.12,10.01,3*1/3.075,3*1.361/3.075,3*0.714/3.075,0,2,0]).reshape(1,-1) , columns = ['KOH (M)','H2SO4 (M)','SSA','ID/IG','%O','%N5','%N6','%NQ','%OtherN','%S','ln(Current Density)'])

#shap.KernelExplainer is used to calculate SHAP values
explainer = shap.KernelExplainer(CVANN.predict, test_input_df)
shap_values = explainer.shap_values(tester_df)

#shap visualization with force_plot
shap.initjs()
shap.force_plot(base_value=explainer.expected_value, shap_values=shap_values,features=tester_df,out_names="Specific Capacitance (F/g)")

#Create shap values table
shap_Table_data={"Feature_values":tester_df.iloc[0,:],
                        "SHAP Values":shap_values.reshape(-1).tolist()}
shap_Table=pd.DataFrame(shap_Table_data)
shap_Table.sort_values(by="SHAP Values",ascending=False)